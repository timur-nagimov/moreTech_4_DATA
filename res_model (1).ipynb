{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fca5123",
   "metadata": {},
   "source": [
    "## API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a270e70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "\n",
    "@app.get(\"/parse\")\n",
    "def parsing():\n",
    "    return json.dumps(_parsing())\n",
    "\n",
    "\n",
    "def _parsing():\n",
    "    articles = []\n",
    "    articles += parse_data_bukhonline()\n",
    "    articles += parse_data_rbc()\n",
    "    articles += parse_data_lenta()\n",
    "    return articles\n",
    "\n",
    "\n",
    "def parse_data_rbc():\n",
    "    articles_dict = {}\n",
    "    cur_time = round(time.time())\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            calc_time = cur_time - i * 86400\n",
    "            url = f'https://www.rbc.ru/v10/ajax/get-news-feed-short/project/rbcnews.uploaded/lastDate/{calc_time}/limit/22'\n",
    "            body = requests.get(url)\n",
    "            raw_body_list = json.loads(body.text)['items']\n",
    "\n",
    "            for body in raw_body_list:\n",
    "                soup = BeautifulSoup(body['html'], \"html.parser\")\n",
    "                try:\n",
    "                    article = {\n",
    "                        'title': soup.find_all('span')[2].text.replace('  ', '').strip('\\n'),\n",
    "                        'link': re.findall(r'href=\\\"(.*)\\\"', str(soup.find_all('a')[1]))[0],\n",
    "                    }\n",
    "                    articles_dict[re.findall(r'id=\\\"(.*)\\\"', str(soup))[0]] = article\n",
    "                except:\n",
    "                    continue\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "\n",
    "    articles = []\n",
    "    for article in articles_dict.values():\n",
    "        article_body = requests.get(article['link'])\n",
    "        article_soup = BeautifulSoup(article_body.text, \"html.parser\")\n",
    "        article['full_info'] = article_soup.find_all('p')[0].text\n",
    "        try:\n",
    "            article['datetime'] = re.findall(r'datetime=\\\"(.*)\\\"', str(article_soup.find_all('time')[0]))[0].split('+')[\n",
    "                0]\n",
    "        except:\n",
    "            article['datetime'] = None\n",
    "        articles.append(article)\n",
    "\n",
    "    return articles\n",
    "\n",
    "\n",
    "def parse_data_lenta():\n",
    "    articles = []\n",
    "    today = datetime.datetime.now()\n",
    "    cur_date = datetime.datetime.now() - datetime.timedelta(days=3)\n",
    "    while today.day != cur_date.day or today.month != cur_date.month or today.year != cur_date.year:\n",
    "        month = cur_date.month if len(str(cur_date.month)) == 2 else f'0{cur_date.month}'\n",
    "        day = cur_date.day if len(str(cur_date.day)) == 2 else f'0{cur_date.day}'\n",
    "        url = f'https://lenta.ru/{cur_date.year}/{month}/{day}/'\n",
    "        print(url)\n",
    "        lenta_page = requests.get(url)\n",
    "        lenta_soup = BeautifulSoup(lenta_page.text, \"html.parser\")\n",
    "        arch_articles = lenta_soup.find_all('ul')[3].find_all('li')\n",
    "        for article in arch_articles:\n",
    "            try:\n",
    "                link = re.findall(r'href=\\\"(.*)\\\"', str(article))[0].split('\\\"')[0]\n",
    "                if not link.startswith('https://lenta.ru'):\n",
    "                    link = 'https://lenta.ru' + link\n",
    "                parsed_dates = re.findall(r'\\d{4}\\/\\d{2}\\/\\d{2}', link)[0].split('\\\"')[0].split('/')\n",
    "            except:\n",
    "                continue\n",
    "            try:\n",
    "                art_json = {\n",
    "                    'title': article.find_all('span')[0].text,\n",
    "                    'link': link,\n",
    "                    'datetime': datetime.datetime(year=int(parsed_dates[0]), month=int(parsed_dates[1]),\n",
    "                                                  day=int(parsed_dates[2]))\n",
    "                }\n",
    "                articles.append(art_json)\n",
    "            except:\n",
    "                continue\n",
    "        cur_date += datetime.timedelta(days=1)\n",
    "\n",
    "    for article in articles:\n",
    "        art_body = requests.get(article['link'])\n",
    "        article['full_info'] = BeautifulSoup(art_body.text, \"html.parser\").text\n",
    "\n",
    "    return articles\n",
    "\n",
    "def parse_data_bukhonline():\n",
    "    request_works = True\n",
    "    page = 1\n",
    "    articles = []\n",
    "    max_pages = 3\n",
    "    while request_works and page <= max_pages:\n",
    "        URL = f'https://www.buhonline.ru/ajax/pub/news?lastPublicationWithSameDataIds=&lastPublicationHasImage=false&hasMore=true&page={page}&exceptIds=0&tagId='\n",
    "        resp = requests.get(URL)\n",
    "        try:\n",
    "            jsoned_resp = json.loads(resp.text)\n",
    "            html = jsoned_resp['html']\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            containers = []\n",
    "            for div in soup.find_all(\"div\", {'class': 'tile tile_other-publications tile_max-w-700'}):\n",
    "                containers.append(div)\n",
    "\n",
    "            for container in containers:\n",
    "                jsoned_article = {\n",
    "                    'name': container.find(\"a\").text.replace(u'\\xa0', u' '),\n",
    "                    'link': 'https://www.buhonline.ru' + str(re.findall(r'\\\"(.*)\\\"', str(container.find(\"a\")))[0]),\n",
    "                    'small_info': container.find('p').text.replace(u'\\xa0', u' '),\n",
    "                }\n",
    "                articles.append(jsoned_article)\n",
    "            page += 1\n",
    "        except:\n",
    "            request_works = False\n",
    "\n",
    "    for article in articles:\n",
    "        full_page = requests.get(article['link'])\n",
    "        soup = BeautifulSoup(full_page.text, \"html.parser\")\n",
    "        full_text = ''\n",
    "        for p in soup.find_all('p'):\n",
    "            full_text += p.text.replace(u'\\xa0', u' ')\n",
    "        article['datetime'] = re.findall(r'\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\.\\d{7}', str(soup.find_all('time')))[0]\n",
    "        article['full_info'] = full_text\n",
    "\n",
    "    return articles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b601f43e",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6c185a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://lenta.ru/2022/10/05/\n",
      "https://lenta.ru/2022/10/06/\n",
      "https://lenta.ru/2022/10/07/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>datetime</th>\n",
       "      <th>full_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Россия первой в мире создала гиперзвуковые ра...</td>\n",
       "      <td>https://lenta.ru/articles/2022/10/05/zvuk/</td>\n",
       "      <td>2022-10-05 00:00:00</td>\n",
       "      <td>«А у нас есть» Россия первой в мире создала ги...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Как избавиться от них: 12 лайфхаков от психол...</td>\n",
       "      <td>https://lenta.ru/articles/2022/10/05/mysli/</td>\n",
       "      <td>2022-10-05 00:00:00</td>\n",
       "      <td>Навязчивые мысли о плохом отравляют жизнь и ру...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Что стоит за обострением армяно-азербайджанск...</td>\n",
       "      <td>https://lenta.ru/articles/2022/10/05/az_arm/</td>\n",
       "      <td>2022-10-05 00:00:00</td>\n",
       "      <td>Не договорились. Что стоит за обострением армя...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>«Кольца власти» и «Дом дракона» подходят к фи...</td>\n",
       "      <td>https://lenta.ru/articles/2022/10/05/dragons_v...</td>\n",
       "      <td>2022-10-05 00:00:00</td>\n",
       "      <td>Дракона мать. «Кольца власти» и «Дом дракона» ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Где отдыхала элита СССР и как были устроены в...</td>\n",
       "      <td>https://lenta.ru/articles/2022/10/05/gosdachi/</td>\n",
       "      <td>2022-10-05 00:00:00</td>\n",
       "      <td>Здесь был генсек. Где отдыхала элита СССР и ка...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>«Яндекс» объяснил исчезновение с карт границ р...</td>\n",
       "      <td>https://www.rbc.ru/technology_and_media/06/10/...</td>\n",
       "      <td>2022-10-06T17:09:15</td>\n",
       "      <td>Основные сценарии использования карт «Яндекса»...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Индексы США выросли после данных по заявкам на...</td>\n",
       "      <td>https://quote.ru/news/article/633ecf509a794775...</td>\n",
       "      <td>2022-10-06T17:07:43</td>\n",
       "      <td>Американские фондовые индексы выросли в начале...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Роскомнадзор ограничил доступ к сайту «вселенн...</td>\n",
       "      <td>https://www.rbc.ru/politics/06/10/2022/633ed80...</td>\n",
       "      <td>2022-10-06T17:02:29</td>\n",
       "      <td>Роскомнадзор по требованию Генпрокуратуры огра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Reuters узнал о предложении группы стран ЕС вв...</td>\n",
       "      <td>https://www.rbc.ru/economics/06/10/2022/633ecf...</td>\n",
       "      <td>2022-10-06T16:57:29</td>\n",
       "      <td>Польша, Италия, Греция и другие страны ЕС подг...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Российские военные сбили выпущенные по Антонов...</td>\n",
       "      <td>https://www.rbc.ru/politics/06/10/2022/633edd4...</td>\n",
       "      <td>2022-10-06T16:56:13</td>\n",
       "      <td>Российская система противовоздушной обороны (П...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0    Россия первой в мире создала гиперзвуковые ра...   \n",
       "1    Как избавиться от них: 12 лайфхаков от психол...   \n",
       "2    Что стоит за обострением армяно-азербайджанск...   \n",
       "3    «Кольца власти» и «Дом дракона» подходят к фи...   \n",
       "4    Где отдыхала элита СССР и как были устроены в...   \n",
       "..                                                ...   \n",
       "61  «Яндекс» объяснил исчезновение с карт границ р...   \n",
       "62  Индексы США выросли после данных по заявкам на...   \n",
       "63  Роскомнадзор ограничил доступ к сайту «вселенн...   \n",
       "64  Reuters узнал о предложении группы стран ЕС вв...   \n",
       "65  Российские военные сбили выпущенные по Антонов...   \n",
       "\n",
       "                                                 link             datetime  \\\n",
       "0          https://lenta.ru/articles/2022/10/05/zvuk/  2022-10-05 00:00:00   \n",
       "1         https://lenta.ru/articles/2022/10/05/mysli/  2022-10-05 00:00:00   \n",
       "2        https://lenta.ru/articles/2022/10/05/az_arm/  2022-10-05 00:00:00   \n",
       "3   https://lenta.ru/articles/2022/10/05/dragons_v...  2022-10-05 00:00:00   \n",
       "4      https://lenta.ru/articles/2022/10/05/gosdachi/  2022-10-05 00:00:00   \n",
       "..                                                ...                  ...   \n",
       "61  https://www.rbc.ru/technology_and_media/06/10/...  2022-10-06T17:09:15   \n",
       "62  https://quote.ru/news/article/633ecf509a794775...  2022-10-06T17:07:43   \n",
       "63  https://www.rbc.ru/politics/06/10/2022/633ed80...  2022-10-06T17:02:29   \n",
       "64  https://www.rbc.ru/economics/06/10/2022/633ecf...  2022-10-06T16:57:29   \n",
       "65  https://www.rbc.ru/politics/06/10/2022/633edd4...  2022-10-06T16:56:13   \n",
       "\n",
       "                                            full_info  \n",
       "0   «А у нас есть» Россия первой в мире создала ги...  \n",
       "1   Навязчивые мысли о плохом отравляют жизнь и ру...  \n",
       "2   Не договорились. Что стоит за обострением армя...  \n",
       "3   Дракона мать. «Кольца власти» и «Дом дракона» ...  \n",
       "4   Здесь был генсек. Где отдыхала элита СССР и ка...  \n",
       "..                                                ...  \n",
       "61  Основные сценарии использования карт «Яндекса»...  \n",
       "62  Американские фондовые индексы выросли в начале...  \n",
       "63  Роскомнадзор по требованию Генпрокуратуры огра...  \n",
       "64  Польша, Италия, Греция и другие страны ЕС подг...  \n",
       "65  Российская система противовоздушной обороны (П...  \n",
       "\n",
       "[159 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = parse_data_lenta()\n",
    "predict_df_lenta = pd.DataFrame(a)\n",
    "\n",
    "a = parse_data_rbc()\n",
    "predict_df_rbc = pd.DataFrame(a)\n",
    "\n",
    "predict_df = pd.concat([predict_df_lenta, predict_df_rbc])\n",
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "492ba952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/timur/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words=stopwords.words(\"russian\")\n",
    "\n",
    "def cleaning(text):\n",
    "    text = re.sub(r'[^\\w\\s]+|[\\d]+', r'',text).strip()\n",
    "    cleaned_text=[]\n",
    "    morr = MorphAnalyzer()\n",
    "    tokens_list=text.split()\n",
    "    for token in tokens_list:\n",
    "        token_small=token.lower() #converting to lower case\n",
    "\n",
    "        if token_small not in stop_words:\n",
    "            cleaned_text.append(morr.parse(token_small)[0].normal_form)\n",
    "    clean_text=\" \".join(cleaned_text)\n",
    "    return clean_text\n",
    "\n",
    "def tokenize(text):\n",
    "    split=re.split(\"\\W+\",text) \n",
    "    return split\n",
    "\n",
    "# клининг новых данных\n",
    "predict_df['clean_info'] = predict_df['full_info'].apply(lambda x: cleaning(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "697e24df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>datetime</th>\n",
       "      <th>full_info</th>\n",
       "      <th>clean_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Россия первой в мире создала гиперзвуковые ра...</td>\n",
       "      <td>https://lenta.ru/articles/2022/10/05/zvuk/</td>\n",
       "      <td>2022-10-05 00:00:00</td>\n",
       "      <td>«А у нас есть» Россия первой в мире создала ги...</td>\n",
       "      <td>россия первый мир создать гиперзвуковой ракета...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Как избавиться от них: 12 лайфхаков от психол...</td>\n",
       "      <td>https://lenta.ru/articles/2022/10/05/mysli/</td>\n",
       "      <td>2022-10-05 00:00:00</td>\n",
       "      <td>Навязчивые мысли о плохом отравляют жизнь и ру...</td>\n",
       "      <td>навязчивый мысль плохой отравлять жизнь рушить...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Что стоит за обострением армяно-азербайджанск...</td>\n",
       "      <td>https://lenta.ru/articles/2022/10/05/az_arm/</td>\n",
       "      <td>2022-10-05 00:00:00</td>\n",
       "      <td>Не договорились. Что стоит за обострением армя...</td>\n",
       "      <td>договориться стоить обострение армяноазербайдж...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>«Кольца власти» и «Дом дракона» подходят к фи...</td>\n",
       "      <td>https://lenta.ru/articles/2022/10/05/dragons_v...</td>\n",
       "      <td>2022-10-05 00:00:00</td>\n",
       "      <td>Дракона мать. «Кольца власти» и «Дом дракона» ...</td>\n",
       "      <td>дракон мать кольцо власть дом дракон подходить...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Где отдыхала элита СССР и как были устроены в...</td>\n",
       "      <td>https://lenta.ru/articles/2022/10/05/gosdachi/</td>\n",
       "      <td>2022-10-05 00:00:00</td>\n",
       "      <td>Здесь был генсек. Где отдыхала элита СССР и ка...</td>\n",
       "      <td>генсек отдыхать элита ссср устроить вилла сове...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Россия первой в мире создала гиперзвуковые ра...   \n",
       "1   Как избавиться от них: 12 лайфхаков от психол...   \n",
       "2   Что стоит за обострением армяно-азербайджанск...   \n",
       "3   «Кольца власти» и «Дом дракона» подходят к фи...   \n",
       "4   Где отдыхала элита СССР и как были устроены в...   \n",
       "\n",
       "                                                link             datetime  \\\n",
       "0         https://lenta.ru/articles/2022/10/05/zvuk/  2022-10-05 00:00:00   \n",
       "1        https://lenta.ru/articles/2022/10/05/mysli/  2022-10-05 00:00:00   \n",
       "2       https://lenta.ru/articles/2022/10/05/az_arm/  2022-10-05 00:00:00   \n",
       "3  https://lenta.ru/articles/2022/10/05/dragons_v...  2022-10-05 00:00:00   \n",
       "4     https://lenta.ru/articles/2022/10/05/gosdachi/  2022-10-05 00:00:00   \n",
       "\n",
       "                                           full_info  \\\n",
       "0  «А у нас есть» Россия первой в мире создала ги...   \n",
       "1  Навязчивые мысли о плохом отравляют жизнь и ру...   \n",
       "2  Не договорились. Что стоит за обострением армя...   \n",
       "3  Дракона мать. «Кольца власти» и «Дом дракона» ...   \n",
       "4  Здесь был генсек. Где отдыхала элита СССР и ка...   \n",
       "\n",
       "                                          clean_info  \n",
       "0  россия первый мир создать гиперзвуковой ракета...  \n",
       "1  навязчивый мысль плохой отравлять жизнь рушить...  \n",
       "2  договориться стоить обострение армяноазербайдж...  \n",
       "3  дракон мать кольцо власть дом дракон подходить...  \n",
       "4  генсек отдыхать элита ссср устроить вилла сове...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e54697",
   "metadata": {},
   "source": [
    "## fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "482bf6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "00c9e0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.load_model('model/fasttext_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f8c92dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df['pred_class'] = predict_df['clean_info'].apply(model.predict)\n",
    "\n",
    "predict_df['pred_class'] = predict_df['pred_class'].apply(lambda x: str(list(x)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dc4e0357",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df['pred_class']= predict_df['pred_class'].apply(lambda x: x[x.rfind('__')+2: x.find(',')-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6a38639f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other    144\n",
       "buh       15\n",
       "Name: pred_class, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df['pred_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaaae55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c6587e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "896ae912",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "762d0404",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clean = []\n",
    "for index, row in predict_df.iterrows():\n",
    "        text_clean.append(row['clean_info'].split()) # ТУТ НАДО BUH DF\n",
    "\n",
    "from gensim.models import Phrases\n",
    "bigram = Phrases(text_clean) # Создаем биграммы на основе корпуса\n",
    "trigram = Phrases(bigram[text_clean])# Создаем триграммы на основе корпуса\n",
    "\n",
    "for idx in range(len(text_clean)):\n",
    "    for token in bigram[text_clean[idx]]:\n",
    "        if '_' in token:\n",
    "            # Токен это би грамма, добавим в документ.\n",
    "            text_clean[idx].append(token)\n",
    "    for token in trigram[text_clean[idx]]:\n",
    "        if '_' in token:\n",
    "            # Токен это триграмма, добавим в документ.\n",
    "            text_clean[idx].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b9901abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных токенов: 11328\n",
      "Количество документов: 159\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from numpy import array\n",
    "dictionary = Dictionary(text_clean)\n",
    "#dictionary.filter_extremes(no_below=10, no_above=0.1)\n",
    "#Создадим словарь и корпус для lda модели\n",
    "corpus = [dictionary.doc2bow(doc) for doc in text_clean]\n",
    "print('Количество уникальных токенов: %d' % len(dictionary))\n",
    "print('Количество документов: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e1c888fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "model=LdaMulticore(corpus=corpus,id2word=dictionary, num_topics=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "aad3f970",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/LDA.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "08ebe627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_name = 'myModel.sav'\n",
    "pickle.dump(model, open('model/LDA.model', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d9f123c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Россия'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {}\n",
    "for i in model.show_topics():\n",
    "    a[float(i[1].split('*')[0])] = i[1].split('\"')[1]\n",
    "sorted(a.values(), reverse=True)[0].capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de21b071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3351af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trend('"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac9d6f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6fc2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71698554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3a041f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc0397e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
